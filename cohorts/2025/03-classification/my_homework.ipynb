{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "> Note: sometimes your answer doesn't match one of the options exactly.\n",
    "> That's fine.\n",
    "> Select the option that's closest to your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mutual_info_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "In this homework, we will use the lead scoring dataset [Bank Marketing dataset](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv).\n",
    "\n",
    "You can download it with `wget`:\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
    "```\n",
    "\n",
    "In this dataset, our desired target for the classification task will be the `converted` variable - has the client signed up to the platform or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-15 14:30:18--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78,98K  --.-KB/s    in 0,03s   \n",
      "\n",
      "2025-10-15 14:30:18 (2,48 MB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = \"course_lead_scoring.csv\"\n",
    "!wget -O {csv_file_name} https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "- Check if the missing values are present in the features.\n",
    "- If there are missing values:\n",
    "    - For categorical features, replace them with 'NA'\n",
    "    - For numerical features, replace them with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file_name)\n",
    "target = \"converted\"\n",
    "\n",
    "# create list of categorical and numerical features\n",
    "categorical_features = df.select_dtypes(\n",
    "    include=[\"object\", \"category\", \"bool\"]\n",
    ").columns.tolist()\n",
    "numerical_features = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "if target in categorical_features:\n",
    "    categorical_features.remove(target)\n",
    "elif target in numerical_features:\n",
    "    numerical_features.remove(target)\n",
    "\n",
    "df[categorical_features] = df[categorical_features].fillna(\"NA\")\n",
    "df[numerical_features] = df[numerical_features].fillna(0.0)\n",
    "\n",
    "# sanity check\n",
    "if len(df.columns) - len(categorical_features) - len(numerical_features) - 1 != 0:\n",
    "    raise RuntimeWarning(\"Something is off with the number of columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "What is the most frequent observation (mode) for the column `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    retail\n",
       "Name: industry, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"industry\"].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `NA`\n",
    "- `technology`\n",
    "- `healthcare`\n",
    "- **`retail`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset.\n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the two features that have the biggest correlation?\n",
    "- `interaction_count` and `lead_score`\n",
    "- `number_of_courses_viewed` and `lead_score`\n",
    "- `number_of_courses_viewed` and `interaction_count`\n",
    "- **`annual_income` and `interaction_count`**\n",
    "\n",
    "Only consider the pairs above when answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('annual_income', 'interaction_count'), np.float64(0.02703647240481443)), (('number_of_courses_viewed', 'interaction_count'), np.float64(-0.023565222882888037)), (('interaction_count', 'lead_score'), np.float64(0.009888182496913131)), (('number_of_courses_viewed', 'lead_score'), np.float64(-0.004878998354681276))]\n",
      "The pair with the highest absolute correlation is ('annual_income', 'interaction_count')\n"
     ]
    }
   ],
   "source": [
    "column_pairs = [\n",
    "    (\"interaction_count\", \"lead_score\"),\n",
    "    (\"number_of_courses_viewed\", \"lead_score\"),\n",
    "    (\"number_of_courses_viewed\", \"interaction_count\"),\n",
    "    (\"annual_income\", \"interaction_count\"),\n",
    "]\n",
    "\n",
    "correlations = {(c1, c2): correlation_matrix.loc[c1, c2] for c1, c2 in column_pairs}\n",
    "\n",
    "sorted_correlations = sorted(\n",
    "    correlations.items(), key=lambda item: abs(item[1]), reverse=True\n",
    ")\n",
    "\n",
    "print(sorted_correlations)\n",
    "print(f\"The pair with the highest absolute correlation is {sorted_correlations[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data\n",
    "- Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "- Make sure that the target value `y` is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative sizes train, val, test: [0.59917921 0.2004104  0.2004104 ]\n"
     ]
    }
   ],
   "source": [
    "def my_split(df, target, test_size, val_size, seed=42):\n",
    "    # split factors\n",
    "    train_size_of_full_train = val_size / (1 - test_size)\n",
    "\n",
    "    df_full_train, df_test = train_test_split(\n",
    "        df, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    df_train, df_val = train_test_split(\n",
    "        df_full_train, test_size=train_size_of_full_train, random_state=seed\n",
    "    )\n",
    "    # train, val, test\n",
    "    return (\n",
    "        df_train.drop(columns=[target]),\n",
    "        df_train[target].values,\n",
    "        df_val.drop(columns=[target]),\n",
    "        df_val[target].values,\n",
    "        df_test.drop(columns=[target]),\n",
    "        df_test[target].values,\n",
    "    )\n",
    "\n",
    "\n",
    "df_train, y_train, df_val, y_val, df_test, y_test = my_split(df, target, 0.2, 0.2)\n",
    "\n",
    "# sanity check\n",
    "print(\n",
    "    f\"relative sizes train, val, test: {np.array([len(df_train), len(df_val), len(df_test)]) / (len(df_train) + len(df_val) + len(df_test))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "- Calculate the mutual information score between `y` and other categorical variables in the dataset. Use the training set only.\n",
    "- Round the scores to 2 decimals using `round(score, 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lead_source', 0.03539624379726594), ('employment_status', 0.012937677269442782), ('industry', 0.011574521435657112), ('location', 0.004464157884038034)]\n",
      "lead_source has the highest mutual information score.\n"
     ]
    }
   ],
   "source": [
    "mutual_information_scores = {\n",
    "    variable: mutual_info_score(y_train, df_train[variable])\n",
    "    for variable in categorical_features\n",
    "}\n",
    "mutual_information_scores_sorted = sorted(\n",
    "    mutual_information_scores.items(), key=lambda item: item[1], reverse=True\n",
    ")\n",
    "print(mutual_information_scores_sorted)\n",
    "print(\n",
    "    f\"{mutual_information_scores_sorted[0][0]} has the highest mutual information score.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of these variables has the biggest mutual information score?\n",
    "- `industry`\n",
    "- `location`\n",
    "- **`lead_source`**\n",
    "- `employment_status`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "    - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = df_train.to_dict(orient=\"records\")\n",
    "X_train_encoded = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val.to_dict(orient=\"records\")\n",
    "X_val_encoded = dv.transform(val_dict)\n",
    "\n",
    "\n",
    "model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val_encoded)\n",
    "baseline_accuracy = (y_val == y_pred).mean()\n",
    "round(baseline_accuracy, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What accuracy did you get?\n",
    "- 0.64\n",
    "- **0.74**\n",
    "- 0.84\n",
    "- 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "- Let's find the least useful feature using the *feature elimination* technique.\n",
    "- Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('industry', np.float64(0.0)), ('employment_status', np.float64(0.0034129692832763903)), ('lead_score', np.float64(-0.0068259385665528916))]\n",
      "industry has the smallest impact\n"
     ]
    }
   ],
   "source": [
    "features_to_drop = [\"industry\", \"employment_status\", \"lead_score\"]\n",
    "\n",
    "feature_impacts = {}\n",
    "for col in features_to_drop:\n",
    "    df_train_dropped_col = df_train.drop(columns=[col])\n",
    "    df_val_dropped_col = df_val.drop(columns=[col])\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    train_dict = df_train_dropped_col.to_dict(orient=\"records\")\n",
    "    X_train_encoded = dv.fit_transform(train_dict)\n",
    "\n",
    "    val_dict = df_val_dropped_col.to_dict(orient=\"records\")\n",
    "    X_val_encoded = dv.transform(val_dict)\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42\n",
    "    )\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val_encoded)\n",
    "    accuracy = (y_val == y_pred).mean()\n",
    "    feature_impacts[col] = baseline_accuracy - accuracy\n",
    "\n",
    "sorted_feature_impacts = sorted(\n",
    "    feature_impacts.items(), key=lambda item: abs(item[1]), reverse=False\n",
    ")\n",
    "print(sorted_feature_impacts)\n",
    "print(f\"{sorted_feature_impacts[0][0]} has the smallest impact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Which of following feature has the smallest difference?\n",
    "- **`'industry'`**\n",
    "- `'employment_status'`\n",
    "- `'lead_score'`\n",
    "> **Note**: The difference doesn't have to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "- Train models using all the features as in Q4.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.01, np.float64(0.7)), (0.1, np.float64(0.7)), (1, np.float64(0.7)), (10, np.float64(0.7)), (100, np.float64(0.7))]\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = df_train.to_dict(orient=\"records\")\n",
    "X_train_encoded = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val.to_dict(orient=\"records\")\n",
    "X_val_encoded = dv.transform(val_dict)\n",
    "\n",
    "c_to_accuracy = {}\n",
    "for c in c_values:\n",
    "    model = LogisticRegression(solver=\"liblinear\", C=c, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val_encoded)\n",
    "    acc = (y_val == y_pred).mean()\n",
    "    c_to_accuracy[c] = acc.round(3)\n",
    "\n",
    "sorted_accuracies = sorted(\n",
    "    c_to_accuracy.items(), key=lambda item: item[1], reverse=True\n",
    ")\n",
    "print(sorted_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of these `C` leads to the best accuracy on the validation set?\n",
    "- **0.01**\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "- 100\n",
    "> **Note**: If there are multiple options, select the smallest `C`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the Results\n",
    "- Submit your results [here](https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw03)\n",
    "- If your answer doesn't match options exactly, select the closest one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
