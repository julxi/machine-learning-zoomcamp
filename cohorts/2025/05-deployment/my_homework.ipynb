{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fffadba",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of the options exactly. \n",
    "> That's fine. \n",
    "> Select the option that's closest to your solution.\n",
    "\n",
    "We recommend using python 3.12 or 3.13 in this homework.\n",
    "\n",
    "In this homework, we're going to continue working with the lead scoring dataset. You don't need the dataset: we will provide the model for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff821d71",
   "metadata": {},
   "source": [
    "## My setup with `uv`\n",
    "\n",
    "I aim to create two virtual environments:\n",
    "- One in the project root â€“ the standard Python virtual environment.\n",
    "- Another in the homework folder (`cohorts/2025/05-deployment`) using `uv`\n",
    "\n",
    "Here's how I set it up (maybe not the best way to do it though):\n",
    "1.  I activate the standard virtual environment (created with `venv`) and install `uv`\n",
    "```bash (venv)\n",
    "pip install uv\n",
    "```\n",
    "2. Then, I navigate to the homework folder and initialize a new `uv` project:\n",
    "```bash (venv)\n",
    "uv init\n",
    "```\n",
    "\n",
    "***Note:*** At this point there is no virtual environment managed by `uv` yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304985cc",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Install `uv`\n",
    "* What's the version of uv you installed?\n",
    "* Use `--version` to find out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03646d21",
   "metadata": {},
   "source": [
    "### Solution 1\n",
    "\n",
    "I have already installed `uv` above.\n",
    "So I only have to execute (in the activated `venv`)\n",
    "```bash (venv)\n",
    "uv --version\n",
    "```\n",
    "Which returns\n",
    "```\n",
    "uv 0.9.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d76bcb",
   "metadata": {},
   "source": [
    "## Initialize an empty uv project\n",
    "\n",
    "You should create an empty folder for homework\n",
    "and do it there. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17a4c42",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Use uv to install Scikit-Learn version 1.6.1 \n",
    "* What's the first hash for Scikit-Learn you get in the lock file?\n",
    "* Include the entire string starting with sha256:, don't include quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9022694",
   "metadata": {},
   "source": [
    "### Solution 2 & Jupyter setup\n",
    "\n",
    "I want to do two things:\n",
    "1. do the exercise\n",
    "2. connect this Jupyter notebook with the `uv` managed virtual environment\n",
    "\n",
    "The first part is easy. Just run: (I think you have to be in the homework folder for this and all subsequent `uv add` actions)\n",
    "```bash (venv)\n",
    "uv add scikit-learn==1.6.1\n",
    "```\n",
    "On my setup this always returns a warning\n",
    "```\n",
    "warning: `VIRTUAL_ENV=/home/jx/projects/machine-learning-zoomcamp/venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead\n",
    "```\n",
    "this warning indicates that uv detected a different active venv; it is safe to ignore because we want to stay in the Python venv. Of course having multiple active venvs is a bit confusing.\n",
    "\n",
    "After installing our first package with `uv` it also creates a virtual environment in this homework folder. Now we have two virtual environments:\n",
    "- standard Python virtual environment in `venv/bin/activate`. This one has `uv` installed.\n",
    "- `uv` managed virtual environment in `cohorts/2025/05-deployment/.venv/bin/activate`. This one has `scikit-learn==1.6.1` installed.\n",
    "\n",
    "**Note**: To activate `uv` virtual environment from the project root you can type `cohorts/2025/05-deployment/.venv/bin/activate` in the console. For leaving the environment you can type `deactivate`.\n",
    "\n",
    "Next I want to use the `uv` virtual environment for this notebook. First I have to install `ipykernel`:\n",
    "```bash (venv)\n",
    "uv add ipykernel\n",
    "```\n",
    "I'm using vs code to run the `.ipynb`s. My vscode doesn't find the `uv`'virtual enviornment automatically. I had to press `ctrn + shift + P` and select `Python: Select Interpreter` there I could choose `select interpreter path`. Here I used `cohorts/2025/05-deployment/.venv/bin/python`. This gave an error but it selectable for the notebook.\n",
    "\n",
    "Now we can check if we are running the right version of scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4824ff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81165b89",
   "metadata": {},
   "source": [
    "\n",
    "## Models\n",
    "\n",
    "We have prepared a pipeline with a dictionary vectorizer and a model.\n",
    "\n",
    "It was trained (roughly) using this code:\n",
    "\n",
    "```python\n",
    "categorical = ['lead_source']\n",
    "numeric = ['number_of_courses_viewed', 'annual_income']\n",
    "\n",
    "df[categorical] = df[categorical].fillna('NA')\n",
    "df[numeric] = df[numeric].fillna(0)\n",
    "\n",
    "train_dict = df[categorical + numeric].to_dict(orient='records')\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "pipeline.fit(train_dict, y_train)\n",
    "```\n",
    "\n",
    "> **Note**: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download it [here](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2025/05-deployment/pipeline_v1.bin).\n",
    "\n",
    "With `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef72595",
   "metadata": {},
   "source": [
    "When downloading the file we have to make sure that it lands in the right folder for this notebook to find it. The notebook looks for files in the project root as we can see here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d8881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/jx/projects/machine-learning-zoomcamp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757098c7",
   "metadata": {},
   "source": [
    "The current working directory is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a3fe57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jx/projects/machine-learning-zoomcamp\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caea433",
   "metadata": {},
   "source": [
    "So everything is fine and we can just execute the command from below (best just once):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d715bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c1b4f7",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let's use the model!\n",
    "\n",
    "* Write a script for loading the pipeline with pickle\n",
    "* Score this record:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"lead_source\": \"paid_ads\",\n",
    "    \"number_of_courses_viewed\": 2,\n",
    "    \"annual_income\": 79276.0\n",
    "}\n",
    "```\n",
    "\n",
    "What's the probability that this lead will convert? \n",
    "\n",
    "* 0.333\n",
    "* 0.533\n",
    "* 0.733\n",
    "* 0.933\n",
    "\n",
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```bash\n",
    "$ md5sum pipeline_v1.bin\n",
    "7d17d2e4dfbaf1e408e1a62e6e880d49 *pipeline_v1.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d578d8",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "373f0316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classes [0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.46639273, 0.53360727]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "with open(\"pipeline_v1.bin\", \"rb\") as file_in:\n",
    "    pipeline: Pipeline = pickle.load(file_in)\n",
    "\n",
    "record = {\n",
    "    \"lead_source\": \"paid_ads\",\n",
    "    \"number_of_courses_viewed\": 2,\n",
    "    \"annual_income\": 79276.0,\n",
    "}\n",
    "\n",
    "print(\"The classes\", pipeline.classes_)\n",
    "pipeline.predict_proba(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67e10b",
   "metadata": {},
   "source": [
    "So the correct probability is:\n",
    "\n",
    "* 0.333\n",
    "* **0.533**\n",
    "* 0.733\n",
    "* 0.933"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756acaca",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install FastAPI\n",
    "* Write FastAPI code for serving the model\n",
    "* Now score this client using `requests`:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\n",
    "    \"lead_source\": \"organic_search\",\n",
    "    \"number_of_courses_viewed\": 4,\n",
    "    \"annual_income\": 80304.0\n",
    "}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a subscription?\n",
    "\n",
    "* 0.334\n",
    "* 0.534\n",
    "* 0.734\n",
    "* 0.934"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4640a92b",
   "metadata": {},
   "source": [
    "### Solution 4\n",
    "\n",
    "We have to install three packages for this\n",
    "```bash (venv)\n",
    "uv add requests fastapi[standard] uvicorn\n",
    "```\n",
    "\n",
    "- requests: the exercise asks us to use requests to send the html request to the server\n",
    "- fastapi: to write the webserver in python\n",
    "- uvicorn: to host the webserver. We could actually also use fastapi for this but we need uvicorn later anyway\n",
    "\n",
    "After that we have to execute `question_4_server.py` (make sure to be in the homework folder, otherwise `uv run` wont find `uvicorn`)\n",
    "\n",
    "```bash venv\n",
    "uv run uvicorn question_4_server:app\n",
    "```\n",
    "\n",
    "Then it should show you on which port it's running and we can execute the following code to get the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813378c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prob': 0.5340417283801275}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8000/predict\"\n",
    "client = {\n",
    "    \"lead_source\": \"organic_search\",\n",
    "    \"number_of_courses_viewed\": 4,\n",
    "    \"annual_income\": 80304.0,\n",
    "}\n",
    "requests.post(url, json=client).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b8c943",
   "metadata": {},
   "source": [
    "So the answer is:\n",
    "\n",
    "* 0.334\n",
    "* **0.534**\n",
    "* 0.734\n",
    "* 0.934"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c8bb9",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "Install [Docker](https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/05-deployment/06-docker.md). \n",
    "We will use it for the next two questions.\n",
    "\n",
    "For these questions, we prepared a base image: `agrigorev/zoomcamp-model:2025`. \n",
    "You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "This image is based on `3.13.5-slim-bookworm` and has\n",
    "a pipeline with logistic regression (a different one)\n",
    "as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "```docker \n",
    "FROM python:3.13.5-slim-bookworm\n",
    "WORKDIR /code\n",
    "COPY pipeline_v2.bin .\n",
    "```\n",
    "\n",
    "We already built it and then pushed it to [`agrigorev/zoomcamp-model:2025`](https://hub.docker.com/r/agrigorev/zoomcamp-model).\n",
    "\n",
    "> **Note**: You don't need to build this docker image, it's just for your reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b2f919",
   "metadata": {},
   "source": [
    "## My Docker setup\n",
    "\n",
    "I can't explain how to install Docker. For Ubuntu I used this guide https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository. But on the official site it says that the recommended way is to install docker desktop. I don't actually know why I've chosen the harder way, but I also learned some linux stuff on the way.\n",
    "\n",
    "I also added my user to the docker group https://docs.docker.com/engine/install/linux-postinstall so I can run docker commands without sudo.\n",
    "\n",
    "Once all of this is done we can do the next exercise.\n",
    "**Note:** I didn't know how to update the shell used in this jupyter notebook and in the end I just restarted my pc before the next exercise (I'm sure there is another way though)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d2175",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Download the base image `agrigorev/zoomcamp-model:2025`. You can easily make it by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "* 45 MB\n",
    "* 121 MB\n",
    "* 245 MB\n",
    "* 330 MB\n",
    "\n",
    "You can get this information when running `docker images` - it'll be in the \"SIZE\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290e5434",
   "metadata": {},
   "source": [
    "### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b112bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025: Pulling from agrigorev/zoomcamp-model\n",
      "Digest: sha256:14d79fde0bbf078eb18c99c2bd007205917b758ec11060b2994963a1e485c2ae\n",
      "Status: Image is up to date for agrigorev/zoomcamp-model:2025\n",
      "docker.io/agrigorev/zoomcamp-model:2025\n"
     ]
    }
   ],
   "source": [
    "! docker pull agrigorev/zoomcamp-model:2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39b57280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                 TAG       IMAGE ID       CREATED        SIZE\n",
      "ml-zoomcamp-homework-05    2025      1f1fe8338dc7   13 hours ago   204MB\n",
      "agrigorev/zoomcamp-model   2025      4a9ecc576ae9   4 days ago     121MB\n",
      "hello-world                latest    1b44b5a3e06a   2 months ago   10.1kB\n"
     ]
    }
   ],
   "source": [
    "! docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687abf3",
   "metadata": {},
   "source": [
    "So the answer is:\n",
    "\n",
    "* 45 MB\n",
    "* **121 MB**\n",
    "* 245 MB\n",
    "* 330 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd67c4c2",
   "metadata": {},
   "source": [
    "## Dockerfile\n",
    "\n",
    "Now create your own `Dockerfile` based on the image we prepared.\n",
    "\n",
    "It should start like that:\n",
    "\n",
    "```docker\n",
    "FROM agrigorev/zoomcamp-model:2025\n",
    "# add your stuff here\n",
    "```\n",
    "\n",
    "Now complete it:\n",
    "\n",
    "* Install all the dependencies from pyproject.toml\n",
    "* Copy your FastAPI script\n",
    "* Run it with uvicorn \n",
    "\n",
    "After that, you can build your docker image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980df7eb",
   "metadata": {},
   "source": [
    "## How I wrote my Dockerfile\n",
    "\n",
    "You can inspect the dockerfile yourself. There are some points though. First let's look at the history of the dockerfile that we downloaded earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a35462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE          CREATED        CREATED BY                                      SIZE      COMMENT\n",
      "4a9ecc576ae9   4 days ago     COPY pipeline_v2.bin . # buildkit               1.3kB     buildkit.dockerfile.v0\n",
      "<missing>      4 days ago     WORKDIR /code                                   0B        buildkit.dockerfile.v0\n",
      "<missing>      4 months ago   CMD [\"python3\"]                                 0B        buildkit.dockerfile.v0\n",
      "<missing>      4 months ago   RUN /bin/sh -c set -eux;  for src in idle3 pâ€¦   36B       buildkit.dockerfile.v0\n",
      "<missing>      4 months ago   RUN /bin/sh -c set -eux;   savedAptMark=\"$(aâ€¦   36.7MB    buildkit.dockerfile.v0\n",
      "<missing>      4 months ago   ENV PYTHON_SHA256=93e583f243454e6e9e4588ca2câ€¦   0B        buildkit.dockerfile.v0\n",
      "<missing>      4 months ago   ENV PYTHON_VERSION=3.13.5                       0B        buildkit.dockerfile.v0\n",
      "<missing>      4 months ago   ENV GPG_KEY=7169605F62C751356D054A26A821E680â€¦   0B        buildkit.dockerfile.v0\n",
      "<missing>      4 months ago   RUN /bin/sh -c set -eux;  apt-get update;  aâ€¦   9.25MB    buildkit.dockerfile.v0\n",
      "<missing>      4 months ago   ENV PATH=/usr/local/bin:/usr/local/sbin:/usrâ€¦   0B        buildkit.dockerfile.v0\n",
      "<missing>      4 months ago   # debian.sh --arch 'amd64' out/ 'bookworm' 'â€¦   74.8MB    debuerreotype 0.15\n"
     ]
    }
   ],
   "source": [
    "! docker history agrigorev/zoomcamp-model:2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4275bb64",
   "metadata": {},
   "source": [
    "So there are two remarks:\n",
    "1. The pipeline is called `pipeline_v2.bin` so the code from exercise 4 wouldn't work as it uses `pipeline_v1.bin`. So made a copy of `question_4_server.py` to `question_6_server.py` which has basically just this one change.\n",
    "2. Since the pipeline_v2.bin is in the current working directory we shouldn't create another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aaf91dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (9/9) FINISHED                                 docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 672B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/agrigorev/zoomcamp-model:2025   0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [1/4] FROM docker.io/agrigorev/zoomcamp-model:2025                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 104B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/4] RUN pip install uv                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/4] COPY [pyproject.toml, uv.lock, ./]                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/4] COPY [question_6_server.py, ./]                           0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:1f1fe8338dc72133564c0982efd4059f8667ea1b851c0  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/ml-zoomcamp-homework-05:2025            0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# build docker image\n",
    "! docker build -t ml-zoomcamp-homework-05:2025 cohorts/2025/05-deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e8d5f",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\n",
    "    \"lead_source\": \"organic_search\",\n",
    "    \"number_of_courses_viewed\": 4,\n",
    "    \"annual_income\": 80304.0\n",
    "}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this lead will convert?\n",
    "\n",
    "* 0.39\n",
    "* 0.59\n",
    "* 0.79\n",
    "* 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647188f",
   "metadata": {},
   "source": [
    "### Solution 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8bd8cd",
   "metadata": {},
   "source": [
    "We have to run docker\n",
    "\n",
    "```bash\n",
    "docker run -p 9696:9696 ml-zoomcamp-homework-05:2025\n",
    "```\n",
    "(we can't really run it here because the process does not terminate, maybe there is a way. but anyway I prefer the bash for this)\n",
    "\n",
    "And then very similarly to before we can just send a request to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276a7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prob': 0.9933071490756734}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:9696/predict\"\n",
    "client = {\n",
    "    \"lead_source\": \"organic_search\",\n",
    "    \"number_of_courses_viewed\": 4,\n",
    "    \"annual_income\": 80304.0,\n",
    "}\n",
    "requests.post(url, json=client).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8711e4b4",
   "metadata": {},
   "source": [
    "So the solution is:\n",
    "\n",
    "* 0.39\n",
    "* 0.59\n",
    "* 0.79\n",
    "* **0.99**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646ad58",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw05\n",
    "* If your answer doesn't match options exactly, select the closest one\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "05-deployment (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
